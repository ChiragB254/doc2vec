{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of documents.\n",
    "data = [\"This is the first document\",\n",
    "        \"This is the second document\",\n",
    "        \"This is the third document\",\n",
    "        \"This is the fourth document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproces the documents, and create TaggedDocuments\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
    "                              tags=[str(i)]) for i,\n",
    "               doc in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['this', 'is', 'the', 'first', 'document'], ['0']>\n",
      "TaggedDocument<['this', 'is', 'the', 'second', 'document'], ['1']>\n",
      "TaggedDocument<['this', 'is', 'the', 'third', 'document'], ['2']>\n",
      "TaggedDocument<['this', 'is', 'the', 'fourth', 'document'], ['3']>\n"
     ]
    }
   ],
   "source": [
    "for i in tagged_data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Doc2vec model\n",
    "model = Doc2Vec(vector_size=20,\n",
    "                min_count=2, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the document vectors\n",
    "document_vectors = [model.infer_vector(\n",
    "    word_tokenize(doc.lower())) for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 : This is the first document\n",
      "Vector: [-0.01142612  0.02129321  0.00438275  0.01593259 -0.01025523 -0.01399397\n",
      "  0.02363143 -0.00929494  0.00280987  0.01716064 -0.00214236 -0.00684456\n",
      "  0.01837697 -0.01073344 -0.01869184  0.01852228 -0.01733654  0.0029314\n",
      "  0.01985864  0.01297776]\n",
      "\n",
      "Document 2 : This is the second document\n",
      "Vector: [ 0.01930039  0.00430071 -0.01087804  0.01039556 -0.01064147 -0.01848278\n",
      "  0.01715824  0.00135932  0.01734472 -0.00040147  0.0055463  -0.00043264\n",
      " -0.01124458 -0.00049775  0.00681238 -0.01269298  0.00231915  0.02265955\n",
      "  0.02137966  0.01878252]\n",
      "\n",
      "Document 3 : This is the third document\n",
      "Vector: [-0.00010546 -0.00347492 -0.0167986  -0.02467314  0.01298489 -0.00870977\n",
      "  0.02024623 -0.00800551  0.00320132  0.00953845 -0.01783402  0.02428336\n",
      "  0.02148232  0.00426813  0.00995438  0.01787821 -0.00371053 -0.01987445\n",
      "  0.01677905 -0.01133107]\n",
      "\n",
      "Document 4 : This is the fourth document\n",
      "Vector: [-0.02009611  0.00455549  0.00353938 -0.02240707 -0.00534018 -0.01515416\n",
      " -0.02247898  0.00825169  0.01899806 -0.01420393 -0.01841566  0.00549114\n",
      "  0.0199536   0.02389451 -0.010204    0.01815356  0.00653369  0.0104725\n",
      " -0.01359539  0.01602874]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  print the document vectors of 20 dimensions\n",
    "for i, doc in enumerate(data):\n",
    "    print(\"Document\", i+1, \":\", doc)\n",
    "    print(\"Vector:\", document_vectors[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_10116\\3295603367.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.similarity(\"0\",\"1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27298784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.similarity(\"0\",\"1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
